{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNv4mLXF3GIh5Q512Mwz7RV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eyG3E7WtaCT","executionInfo":{"status":"ok","timestamp":1710298196510,"user_tz":300,"elapsed":6145,"user":{"displayName":"Rebekah Shaw","userId":"13950451939062782291"}},"outputId":"9a3a5a6f-f06f-4830-f68c-6736819f9bff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Column: APPLICATION_TYPE\n","T3     27037\n","T4      1542\n","T6      1216\n","T5      1173\n","T19     1065\n","T8       737\n","T7       725\n","T10      528\n","T9       156\n","T13       66\n","T12       27\n","T2        16\n","T25        3\n","T14        3\n","T29        2\n","T15        2\n","T17        1\n","Name: APPLICATION_TYPE, dtype: int64\n","--------------------------------------------------\n","Column: CLASSIFICATION\n","C1000    17326\n","C2000     6074\n","C1200     4837\n","C3000     1918\n","C2100     1883\n","         ...  \n","C4120        1\n","C8210        1\n","C2561        1\n","C4500        1\n","C2150        1\n","Name: CLASSIFICATION, Length: 71, dtype: int64\n","--------------------------------------------------\n","Column: ASK_AMT\n","5000        25398\n","10478           3\n","15583           3\n","63981           3\n","6725            3\n","            ...  \n","5371754         1\n","30060           1\n","43091152        1\n","18683           1\n","36500179        1\n","Name: ASK_AMT, Length: 8747, dtype: int64\n","--------------------------------------------------\n","Column: APPLICATION_TYPE\n","T3       27037\n","T4        1542\n","T6        1216\n","T5        1173\n","T19       1065\n","T8         737\n","T7         725\n","T10        528\n","T9         156\n","Other      120\n","Name: APPLICATION_TYPE, dtype: int64\n","--------------------------------------------------\n","Column: CLASSIFICATION\n","C1000    17326\n","C2000     6074\n","C1200     4837\n","C3000     1918\n","C2100     1883\n","C7000      777\n","Other      669\n","C1700      287\n","C4000      194\n","C5000      116\n","C1270      114\n","C2700      104\n","Name: CLASSIFICATION, dtype: int64\n","--------------------------------------------------\n","Column: ASK_AMT\n","5000        25398\n","10478           3\n","15583           3\n","63981           3\n","6725            3\n","            ...  \n","5371754         1\n","30060           1\n","43091152        1\n","18683           1\n","36500179        1\n","Name: ASK_AMT, Length: 8747, dtype: int64\n","--------------------------------------------------\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Read CSV file into a Pandas DataFrame\n","df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n","\n","# Identify target variables and feature variables\n","# Target variables\n","target = df[\"IS_SUCCESSFUL\"]\n","\n","# Feature variables (drop EIN and NAME columns)\n","features = df.drop(columns=[\"EIN\", \"NAME\", \"IS_SUCCESSFUL\"])\n","\n","# Determine the number of unique values for each column\n","unique_counts = features.nunique()\n","\n","# For columns with more than 10 unique values,\n","# determine number of data points for each unique value\n","for column in unique_counts.index:\n","    if unique_counts[column] > 10:\n","        print(\"Column:\", column)\n","        print(features[column].value_counts())\n","        print(\"--------------------------------------------------\")\n","\n","# Based on unique value counts,pick a cutoff point to categorical variables\n","cutoff = 100\n","\n","# Binning \"rare\" categorical variables together in a new value \"Other\"\n","for column in unique_counts.index:\n","    if unique_counts[column] > 10 and features[column].dtype == \"object\":\n","        counts = features[column].value_counts()\n","        rare_values = counts[counts < cutoff].index\n","        features[column] = features[column].apply(lambda x: \"Other\" if x in rare_values else x)\n","\n","# Check if the binning was successful\n","for column in unique_counts.index:\n","    if unique_counts[column] > 10:\n","        print(\"Column:\", column)\n","        print(features[column].value_counts())\n","        print(\"--------------------------------------------------\")\n","\n","# Encode categorical variables using pd.get_dummies()\n","features_encoded = pd.get_dummies(features)\n","\n","# Split preprocessed data into features array (X) and target array (y)\n","X = features_encoded.values\n","y = target.values\n","\n","# Split data into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","\n","# Scale training and testing features datasets\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import ModelCheckpoint"],"metadata":{"id":"LqxUlHONt7C8","executionInfo":{"status":"ok","timestamp":1710298224979,"user_tz":300,"elapsed":3486,"user":{"displayName":"Rebekah Shaw","userId":"13950451939062782291"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Create a neural network model\n","model = Sequential()\n","\n","# Add the first hidden layer\n","model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n","\n","# Add a second hidden layer (optional)\n","# model.add(Dense(units=32, activation='relu'))\n","\n","# Add output layer\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","# Check structure of the model\n","model.summary()\n","\n","# Compile model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Create a callback to save the model's weights every five epochs\n","checkpoint = ModelCheckpoint(\"model_weights.h5\", save_weights_only=True, save_best_only=True, monitor='val_loss', mode='min', verbose=1, period=5)\n","\n","# Train model\n","history = model.fit(\n","    X_train_scaled,\n","    y_train,\n","    epochs=50,\n","    batch_size=256,\n","    validation_data=(X_test_scaled, y_test),\n","    callbacks=[checkpoint]\n",")\n","\n","# Evaluate model using test data\n","model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n","\n","# Save the model to an HDF5 file\n","model.save(\"AlphabetSoupCharity.h5\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rButCKQt_wP","executionInfo":{"status":"ok","timestamp":1710298276892,"user_tz":300,"elapsed":17627,"user":{"displayName":"Rebekah Shaw","userId":"13950451939062782291"}},"outputId":"907e6059-9401-4469-c3f5-61057c067ce1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 64)                3264      \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 3329 (13.00 KB)\n","Trainable params: 3329 (13.00 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","101/101 [==============================] - 2s 6ms/step - loss: 0.6420 - accuracy: 0.6776 - val_loss: 0.5802 - val_accuracy: 0.7237\n","Epoch 2/50\n","101/101 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7245 - val_loss: 0.5671 - val_accuracy: 0.7250\n","Epoch 3/50\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.7271 - val_loss: 0.5606 - val_accuracy: 0.7245\n","Epoch 4/50\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.7294 - val_loss: 0.5570 - val_accuracy: 0.7262\n","Epoch 5/50\n"," 91/101 [==========================>...] - ETA: 0s - loss: 0.5525 - accuracy: 0.7288\n","Epoch 5: val_loss improved from inf to 0.55479, saving model to model_weights.h5\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7297 - val_loss: 0.5548 - val_accuracy: 0.7272\n","Epoch 6/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7289 - val_loss: 0.5548 - val_accuracy: 0.7265\n","Epoch 7/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7304 - val_loss: 0.5533 - val_accuracy: 0.7294\n","Epoch 8/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7316 - val_loss: 0.5543 - val_accuracy: 0.7256\n","Epoch 9/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7304 - val_loss: 0.5525 - val_accuracy: 0.7297\n","Epoch 10/50\n"," 85/101 [========================>.....] - ETA: 0s - loss: 0.5473 - accuracy: 0.7307\n","Epoch 10: val_loss improved from 0.55479 to 0.55256, saving model to model_weights.h5\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7314 - val_loss: 0.5526 - val_accuracy: 0.7249\n","Epoch 11/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7323 - val_loss: 0.5523 - val_accuracy: 0.7269\n","Epoch 12/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7317 - val_loss: 0.5524 - val_accuracy: 0.7293\n","Epoch 13/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7325 - val_loss: 0.5535 - val_accuracy: 0.7277\n","Epoch 14/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7327 - val_loss: 0.5523 - val_accuracy: 0.7270\n","Epoch 15/50\n"," 87/101 [========================>.....] - ETA: 0s - loss: 0.5434 - accuracy: 0.7345\n","Epoch 15: val_loss improved from 0.55256 to 0.55052, saving model to model_weights.h5\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7330 - val_loss: 0.5505 - val_accuracy: 0.7310\n","Epoch 16/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7319 - val_loss: 0.5512 - val_accuracy: 0.7318\n","Epoch 17/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7312 - val_loss: 0.5519 - val_accuracy: 0.7292\n","Epoch 18/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7313 - val_loss: 0.5535 - val_accuracy: 0.7247\n","Epoch 19/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7329 - val_loss: 0.5511 - val_accuracy: 0.7297\n","Epoch 20/50\n"," 82/101 [=======================>......] - ETA: 0s - loss: 0.5449 - accuracy: 0.7315\n","Epoch 20: val_loss did not improve from 0.55052\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7332 - val_loss: 0.5514 - val_accuracy: 0.7303\n","Epoch 21/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7324 - val_loss: 0.5510 - val_accuracy: 0.7277\n","Epoch 22/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7331 - val_loss: 0.5517 - val_accuracy: 0.7285\n","Epoch 23/50\n","101/101 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7328 - val_loss: 0.5522 - val_accuracy: 0.7289\n","Epoch 24/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7330 - val_loss: 0.5502 - val_accuracy: 0.7308\n","Epoch 25/50\n"," 83/101 [=======================>......] - ETA: 0s - loss: 0.5417 - accuracy: 0.7327\n","Epoch 25: val_loss did not improve from 0.55052\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7322 - val_loss: 0.5516 - val_accuracy: 0.7300\n","Epoch 26/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7325 - val_loss: 0.5510 - val_accuracy: 0.7313\n","Epoch 27/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7339 - val_loss: 0.5510 - val_accuracy: 0.7280\n","Epoch 28/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7341 - val_loss: 0.5524 - val_accuracy: 0.7272\n","Epoch 29/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7348 - val_loss: 0.5509 - val_accuracy: 0.7299\n","Epoch 30/50\n"," 87/101 [========================>.....] - ETA: 0s - loss: 0.5401 - accuracy: 0.7358\n","Epoch 30: val_loss improved from 0.55052 to 0.55021, saving model to model_weights.h5\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7336 - val_loss: 0.5502 - val_accuracy: 0.7319\n","Epoch 31/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7341 - val_loss: 0.5511 - val_accuracy: 0.7319\n","Epoch 32/50\n","101/101 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7344 - val_loss: 0.5506 - val_accuracy: 0.7331\n","Epoch 33/50\n","101/101 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7353 - val_loss: 0.5518 - val_accuracy: 0.7279\n","Epoch 34/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7345 - val_loss: 0.5506 - val_accuracy: 0.7319\n","Epoch 35/50\n"," 86/101 [========================>.....] - ETA: 0s - loss: 0.5392 - accuracy: 0.7342\n","Epoch 35: val_loss did not improve from 0.55021\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7340 - val_loss: 0.5505 - val_accuracy: 0.7297\n","Epoch 36/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7355 - val_loss: 0.5513 - val_accuracy: 0.7312\n","Epoch 37/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7334 - val_loss: 0.5510 - val_accuracy: 0.7332\n","Epoch 38/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7345 - val_loss: 0.5504 - val_accuracy: 0.7313\n","Epoch 39/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7350 - val_loss: 0.5508 - val_accuracy: 0.7301\n","Epoch 40/50\n"," 85/101 [========================>.....] - ETA: 0s - loss: 0.5401 - accuracy: 0.7347\n","Epoch 40: val_loss did not improve from 0.55021\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7348 - val_loss: 0.5512 - val_accuracy: 0.7284\n","Epoch 41/50\n","101/101 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7357 - val_loss: 0.5510 - val_accuracy: 0.7284\n","Epoch 42/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7346 - val_loss: 0.5502 - val_accuracy: 0.7310\n","Epoch 43/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7356 - val_loss: 0.5504 - val_accuracy: 0.7329\n","Epoch 44/50\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7353 - val_loss: 0.5519 - val_accuracy: 0.7278\n","Epoch 45/50\n"," 91/101 [==========================>...] - ETA: 0s - loss: 0.5390 - accuracy: 0.7355\n","Epoch 45: val_loss did not improve from 0.55021\n","101/101 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7358 - val_loss: 0.5516 - val_accuracy: 0.7283\n","Epoch 46/50\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7350 - val_loss: 0.5505 - val_accuracy: 0.7306\n","Epoch 47/50\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7349 - val_loss: 0.5515 - val_accuracy: 0.7314\n","Epoch 48/50\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7355 - val_loss: 0.5509 - val_accuracy: 0.7332\n","Epoch 49/50\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7353 - val_loss: 0.5522 - val_accuracy: 0.7310\n","Epoch 50/50\n"," 94/101 [==========================>...] - ETA: 0s - loss: 0.5400 - accuracy: 0.7360\n","Epoch 50: val_loss did not improve from 0.55021\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7359 - val_loss: 0.5505 - val_accuracy: 0.7300\n","268/268 - 0s - loss: 0.5505 - accuracy: 0.7300 - 330ms/epoch - 1ms/step\n","Loss: 0.5505355596542358, Accuracy: 0.7300291657447815\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["\n","# Create a neural network model\n","model = Sequential()\n","\n","# Add first hidden layer with more neurons\n","model.add(Dense(units=128, activation='relu', input_dim=X_train_scaled.shape[1]))\n","\n","# Add second hidden layer with more neurons (optional)\n","model.add(Dense(units=64, activation='relu'))\n","\n","# Add third hidden layer with more neurons (optional)\n","model.add(Dense(units=32, activation='relu'))\n","\n","# Add output layer\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","# Check structure of model\n","model.summary()\n","\n","# Compile model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Create a callback to save the model's weights every five epochs\n","checkpoint = ModelCheckpoint(\"model_weights.h5\", save_weights_only=True, save_best_only=True, monitor='val_loss', mode='min', verbose=1, period=5)\n","\n","# Train model w/ increased epochs\n","history = model.fit(\n","    X_train_scaled,\n","    y_train,\n","    epochs=100,  # Increase the number of epochs\n","    batch_size=256,\n","    validation_data=(X_test_scaled, y_test),\n","    callbacks=[checkpoint]\n",")\n","\n","# Evaluate model using test data\n","model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n","\n","# Save the model to an HDF5 file\n","model.save(\"AlphabetSoupCharity_optimized.h5\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUkJU09LuN1t","executionInfo":{"status":"ok","timestamp":1710298411401,"user_tz":300,"elapsed":83921,"user":{"displayName":"Rebekah Shaw","userId":"13950451939062782291"}},"outputId":"00838610-1c03-46cf-c445-cd9242b7f774"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_2 (Dense)             (None, 128)               6528      \n","                                                                 \n"," dense_3 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 16897 (66.00 KB)\n","Trainable params: 16897 (66.00 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","101/101 [==============================] - 2s 6ms/step - loss: 0.5794 - accuracy: 0.7100 - val_loss: 0.5577 - val_accuracy: 0.7250\n","Epoch 2/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7291 - val_loss: 0.5534 - val_accuracy: 0.7319\n","Epoch 3/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7308 - val_loss: 0.5546 - val_accuracy: 0.7241\n","Epoch 4/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7321 - val_loss: 0.5511 - val_accuracy: 0.7280\n","Epoch 5/100\n"," 97/101 [===========================>..] - ETA: 0s - loss: 0.5467 - accuracy: 0.7309\n","Epoch 5: val_loss improved from inf to 0.55005, saving model to model_weights.h5\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7316 - val_loss: 0.5500 - val_accuracy: 0.7285\n","Epoch 6/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.5440 - accuracy: 0.7336 - val_loss: 0.5494 - val_accuracy: 0.7334\n","Epoch 7/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.7325 - val_loss: 0.5518 - val_accuracy: 0.7294\n","Epoch 8/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.7320 - val_loss: 0.5534 - val_accuracy: 0.7280\n","Epoch 9/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.7343 - val_loss: 0.5524 - val_accuracy: 0.7282\n","Epoch 10/100\n"," 96/101 [===========================>..] - ETA: 0s - loss: 0.5427 - accuracy: 0.7321\n","Epoch 10: val_loss improved from 0.55005 to 0.54856, saving model to model_weights.h5\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7327 - val_loss: 0.5486 - val_accuracy: 0.7318\n","Epoch 11/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7346 - val_loss: 0.5525 - val_accuracy: 0.7278\n","Epoch 12/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7342 - val_loss: 0.5488 - val_accuracy: 0.7298\n","Epoch 13/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7349 - val_loss: 0.5501 - val_accuracy: 0.7301\n","Epoch 14/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7341 - val_loss: 0.5509 - val_accuracy: 0.7307\n","Epoch 15/100\n"," 98/101 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.7347\n","Epoch 15: val_loss did not improve from 0.54856\n","101/101 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7352 - val_loss: 0.5496 - val_accuracy: 0.7296\n","Epoch 16/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7364 - val_loss: 0.5498 - val_accuracy: 0.7310\n","Epoch 17/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5388 - accuracy: 0.7361 - val_loss: 0.5494 - val_accuracy: 0.7307\n","Epoch 18/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5392 - accuracy: 0.7367 - val_loss: 0.5486 - val_accuracy: 0.7347\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7360 - val_loss: 0.5503 - val_accuracy: 0.7289\n","Epoch 20/100\n"," 98/101 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.7364\n","Epoch 20: val_loss did not improve from 0.54856\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7366 - val_loss: 0.5508 - val_accuracy: 0.7283\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7365 - val_loss: 0.5524 - val_accuracy: 0.7291\n","Epoch 22/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7375 - val_loss: 0.5523 - val_accuracy: 0.7264\n","Epoch 23/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7353 - val_loss: 0.5506 - val_accuracy: 0.7320\n","Epoch 24/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7377 - val_loss: 0.5507 - val_accuracy: 0.7286\n","Epoch 25/100\n"," 97/101 [===========================>..] - ETA: 0s - loss: 0.5381 - accuracy: 0.7362\n","Epoch 25: val_loss did not improve from 0.54856\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7371 - val_loss: 0.5519 - val_accuracy: 0.7266\n","Epoch 26/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7367 - val_loss: 0.5515 - val_accuracy: 0.7304\n","Epoch 27/100\n","101/101 [==============================] - 1s 8ms/step - loss: 0.5365 - accuracy: 0.7375 - val_loss: 0.5520 - val_accuracy: 0.7289\n","Epoch 28/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5364 - accuracy: 0.7382 - val_loss: 0.5512 - val_accuracy: 0.7327\n","Epoch 29/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5363 - accuracy: 0.7373 - val_loss: 0.5513 - val_accuracy: 0.7284\n","Epoch 30/100\n"," 94/101 [==========================>...] - ETA: 0s - loss: 0.5380 - accuracy: 0.7372\n","Epoch 30: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 9ms/step - loss: 0.5370 - accuracy: 0.7378 - val_loss: 0.5524 - val_accuracy: 0.7280\n","Epoch 31/100\n","101/101 [==============================] - 1s 11ms/step - loss: 0.5361 - accuracy: 0.7374 - val_loss: 0.5514 - val_accuracy: 0.7276\n","Epoch 32/100\n","101/101 [==============================] - 1s 10ms/step - loss: 0.5353 - accuracy: 0.7392 - val_loss: 0.5526 - val_accuracy: 0.7277\n","Epoch 33/100\n","101/101 [==============================] - 1s 8ms/step - loss: 0.5362 - accuracy: 0.7386 - val_loss: 0.5523 - val_accuracy: 0.7308\n","Epoch 34/100\n","101/101 [==============================] - 1s 8ms/step - loss: 0.5356 - accuracy: 0.7390 - val_loss: 0.5522 - val_accuracy: 0.7329\n","Epoch 35/100\n","101/101 [==============================] - ETA: 0s - loss: 0.5353 - accuracy: 0.7397\n","Epoch 35: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5353 - accuracy: 0.7397 - val_loss: 0.5513 - val_accuracy: 0.7304\n","Epoch 36/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.7382 - val_loss: 0.5517 - val_accuracy: 0.7318\n","Epoch 37/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7389 - val_loss: 0.5516 - val_accuracy: 0.7307\n","Epoch 38/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5346 - accuracy: 0.7384 - val_loss: 0.5510 - val_accuracy: 0.7301\n","Epoch 39/100\n","101/101 [==============================] - 1s 8ms/step - loss: 0.5346 - accuracy: 0.7390 - val_loss: 0.5543 - val_accuracy: 0.7248\n","Epoch 40/100\n"," 97/101 [===========================>..] - ETA: 0s - loss: 0.5342 - accuracy: 0.7393\n","Epoch 40: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5344 - accuracy: 0.7389 - val_loss: 0.5526 - val_accuracy: 0.7291\n","Epoch 41/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5353 - accuracy: 0.7380 - val_loss: 0.5521 - val_accuracy: 0.7308\n","Epoch 42/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5343 - accuracy: 0.7374 - val_loss: 0.5548 - val_accuracy: 0.7289\n","Epoch 43/100\n","101/101 [==============================] - 1s 8ms/step - loss: 0.5345 - accuracy: 0.7390 - val_loss: 0.5531 - val_accuracy: 0.7321\n","Epoch 44/100\n","101/101 [==============================] - 1s 10ms/step - loss: 0.5343 - accuracy: 0.7392 - val_loss: 0.5544 - val_accuracy: 0.7280\n","Epoch 45/100\n"," 95/101 [===========================>..] - ETA: 0s - loss: 0.5337 - accuracy: 0.7391\n","Epoch 45: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5338 - accuracy: 0.7390 - val_loss: 0.5519 - val_accuracy: 0.7289\n","Epoch 46/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5338 - accuracy: 0.7397 - val_loss: 0.5522 - val_accuracy: 0.7304\n","Epoch 47/100\n","101/101 [==============================] - 1s 9ms/step - loss: 0.5339 - accuracy: 0.7401 - val_loss: 0.5533 - val_accuracy: 0.7304\n","Epoch 48/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5342 - accuracy: 0.7390 - val_loss: 0.5551 - val_accuracy: 0.7252\n","Epoch 49/100\n","101/101 [==============================] - 1s 12ms/step - loss: 0.5335 - accuracy: 0.7403 - val_loss: 0.5545 - val_accuracy: 0.7313\n","Epoch 50/100\n"," 93/101 [==========================>...] - ETA: 0s - loss: 0.5319 - accuracy: 0.7396\n","Epoch 50: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5333 - accuracy: 0.7389 - val_loss: 0.5524 - val_accuracy: 0.7304\n","Epoch 51/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5330 - accuracy: 0.7400 - val_loss: 0.5541 - val_accuracy: 0.7307\n","Epoch 52/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5334 - accuracy: 0.7405 - val_loss: 0.5525 - val_accuracy: 0.7312\n","Epoch 53/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7402 - val_loss: 0.5535 - val_accuracy: 0.7285\n","Epoch 54/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7395 - val_loss: 0.5527 - val_accuracy: 0.7291\n","Epoch 55/100\n"," 99/101 [============================>.] - ETA: 0s - loss: 0.5331 - accuracy: 0.7390\n","Epoch 55: val_loss did not improve from 0.54856\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7392 - val_loss: 0.5537 - val_accuracy: 0.7301\n","Epoch 56/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7389 - val_loss: 0.5534 - val_accuracy: 0.7273\n","Epoch 57/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7402 - val_loss: 0.5544 - val_accuracy: 0.7277\n","Epoch 58/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.5326 - accuracy: 0.7403 - val_loss: 0.5521 - val_accuracy: 0.7329\n","Epoch 59/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5324 - accuracy: 0.7394 - val_loss: 0.5584 - val_accuracy: 0.7318\n","Epoch 60/100\n"," 97/101 [===========================>..] - ETA: 0s - loss: 0.5336 - accuracy: 0.7393\n","Epoch 60: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.7398 - val_loss: 0.5545 - val_accuracy: 0.7308\n","Epoch 61/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.5323 - accuracy: 0.7401 - val_loss: 0.5544 - val_accuracy: 0.7300\n","Epoch 62/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7400 - val_loss: 0.5545 - val_accuracy: 0.7300\n","Epoch 63/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5321 - accuracy: 0.7410 - val_loss: 0.5549 - val_accuracy: 0.7270\n","Epoch 64/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5326 - accuracy: 0.7397 - val_loss: 0.5552 - val_accuracy: 0.7304\n","Epoch 65/100\n"," 99/101 [============================>.] - ETA: 0s - loss: 0.5316 - accuracy: 0.7416\n","Epoch 65: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5324 - accuracy: 0.7411 - val_loss: 0.5530 - val_accuracy: 0.7282\n","Epoch 66/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5325 - accuracy: 0.7404 - val_loss: 0.5533 - val_accuracy: 0.7290\n","Epoch 67/100\n","101/101 [==============================] - 1s 8ms/step - loss: 0.5322 - accuracy: 0.7407 - val_loss: 0.5533 - val_accuracy: 0.7305\n","Epoch 68/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5322 - accuracy: 0.7407 - val_loss: 0.5553 - val_accuracy: 0.7294\n","Epoch 69/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5320 - accuracy: 0.7406 - val_loss: 0.5553 - val_accuracy: 0.7299\n","Epoch 70/100\n","100/101 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.7409\n","Epoch 70: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.7411 - val_loss: 0.5552 - val_accuracy: 0.7308\n","Epoch 71/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7409 - val_loss: 0.5548 - val_accuracy: 0.7297\n","Epoch 72/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7406 - val_loss: 0.5564 - val_accuracy: 0.7284\n","Epoch 73/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7408 - val_loss: 0.5564 - val_accuracy: 0.7289\n","Epoch 74/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7407 - val_loss: 0.5558 - val_accuracy: 0.7283\n","Epoch 75/100\n"," 95/101 [===========================>..] - ETA: 0s - loss: 0.5310 - accuracy: 0.7414\n","Epoch 75: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.7413 - val_loss: 0.5549 - val_accuracy: 0.7265\n","Epoch 76/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7409 - val_loss: 0.5559 - val_accuracy: 0.7298\n","Epoch 77/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7407 - val_loss: 0.5546 - val_accuracy: 0.7296\n","Epoch 78/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5314 - accuracy: 0.7404 - val_loss: 0.5561 - val_accuracy: 0.7291\n","Epoch 79/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.7413 - val_loss: 0.5543 - val_accuracy: 0.7291\n","Epoch 80/100\n"," 92/101 [==========================>...] - ETA: 0s - loss: 0.5322 - accuracy: 0.7395\n","Epoch 80: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5312 - accuracy: 0.7405 - val_loss: 0.5557 - val_accuracy: 0.7310\n","Epoch 81/100\n","101/101 [==============================] - 1s 9ms/step - loss: 0.5314 - accuracy: 0.7410 - val_loss: 0.5568 - val_accuracy: 0.7289\n","Epoch 82/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5316 - accuracy: 0.7417 - val_loss: 0.5545 - val_accuracy: 0.7305\n","Epoch 83/100\n","101/101 [==============================] - 1s 8ms/step - loss: 0.5306 - accuracy: 0.7407 - val_loss: 0.5548 - val_accuracy: 0.7304\n","Epoch 84/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5312 - accuracy: 0.7405 - val_loss: 0.5559 - val_accuracy: 0.7276\n","Epoch 85/100\n"," 96/101 [===========================>..] - ETA: 0s - loss: 0.5316 - accuracy: 0.7409\n","Epoch 85: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5310 - accuracy: 0.7413 - val_loss: 0.5571 - val_accuracy: 0.7303\n","Epoch 86/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5311 - accuracy: 0.7411 - val_loss: 0.5555 - val_accuracy: 0.7301\n","Epoch 87/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5307 - accuracy: 0.7414 - val_loss: 0.5578 - val_accuracy: 0.7311\n","Epoch 88/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5310 - accuracy: 0.7416 - val_loss: 0.5563 - val_accuracy: 0.7277\n","Epoch 89/100\n","101/101 [==============================] - 1s 11ms/step - loss: 0.5307 - accuracy: 0.7408 - val_loss: 0.5568 - val_accuracy: 0.7300\n","Epoch 90/100\n"," 96/101 [===========================>..] - ETA: 0s - loss: 0.5310 - accuracy: 0.7400\n","Epoch 90: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 9ms/step - loss: 0.5308 - accuracy: 0.7408 - val_loss: 0.5552 - val_accuracy: 0.7297\n","Epoch 91/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7416 - val_loss: 0.5579 - val_accuracy: 0.7300\n","Epoch 92/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.7411 - val_loss: 0.5580 - val_accuracy: 0.7304\n","Epoch 93/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5308 - accuracy: 0.7409 - val_loss: 0.5569 - val_accuracy: 0.7275\n","Epoch 94/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.5302 - accuracy: 0.7419 - val_loss: 0.5573 - val_accuracy: 0.7264\n","Epoch 95/100\n"," 95/101 [===========================>..] - ETA: 0s - loss: 0.5305 - accuracy: 0.7418\n","Epoch 95: val_loss did not improve from 0.54856\n","101/101 [==============================] - 1s 7ms/step - loss: 0.5305 - accuracy: 0.7419 - val_loss: 0.5568 - val_accuracy: 0.7304\n","Epoch 96/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7414 - val_loss: 0.5569 - val_accuracy: 0.7283\n","Epoch 97/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7409 - val_loss: 0.5574 - val_accuracy: 0.7283\n","Epoch 98/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7412 - val_loss: 0.5554 - val_accuracy: 0.7296\n","Epoch 99/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7414 - val_loss: 0.5573 - val_accuracy: 0.7284\n","Epoch 100/100\n"," 94/101 [==========================>...] - ETA: 0s - loss: 0.5297 - accuracy: 0.7411\n","Epoch 100: val_loss did not improve from 0.54856\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7411 - val_loss: 0.5595 - val_accuracy: 0.7245\n","268/268 - 0s - loss: 0.5595 - accuracy: 0.7245 - 357ms/epoch - 1ms/step\n","Loss: 0.5595476627349854, Accuracy: 0.7245481014251709\n"]}]}]}